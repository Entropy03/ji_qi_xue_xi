
精准率公式
(p = posihives)
$$precision= tp / tp + fp$$
查全率公式
$$recall= tp  / tp + fn$$
F1 分数
$$F1 = 2 * (精确率 * 召回率) / (精确率 + 召回率)$$

###回归指标
正如前面对问题的回归类型所做的介绍，我们处理的是根据连续数据进行预测的模型。在这里，我们更关注预测的接近程度。

例如，对于身高和体重预测，我们不是很关心模型能否将某人的体重 100% 准确地预测到小于零点几磅，但可能很关心模型如何能始终进行接近的预测（可能与个人的真实体重相差 3-4 磅）。
###平均绝对误差
您可能已回想起，在统计学中可以使用绝对误差来测量误差，以找出预测值与真实值之间的差距。平均绝对误差的计算方法是，将各个样本的绝对误差汇总，然后根据数据点数量求出平均误差。通过将模型的所有绝对值加起来，可以避免因预测值比真实值过高或过低而抵销误差，并能获得用于评估模型的整体误差指标。

有关平均绝对误差和如何在 sklearn 中使用它的更多信息，请查看此链接此处。
###均方误差
均方误差是另一个经常用于测量模型性能的指标。与绝对误差相比，残差（预测值与真实值的差值）被求平方。

对残差求平方的一些好处是，自动将所有误差转换为正数、注重较大的误差而不是较小的误差以及在微积分中是可微的（可让我们找到最小值和最大值）。

有关均方误差和如何在 sklearn 中使用它的更多信息，请查看此链接此处。
###回归分数函数
除了误差指标之外，scikit-learn还包括了两个分数指标，范围通常从0到1，值0为坏，而值1为最好的表现，看起来和分类指标类似，都是数字越接近1.0分数就越好。

其中之一是R2分数，用来计算真值预测的可决系数。在 scikit-learn 里，这也是回归学习器默认的分数方法。

另一个是可释方差分数

虽然眼下我们不会详细探讨这些指标，一个要记住的重点是，回归的默认指标是“分数越高越好”；即，越高的分数表明越好的表现。而当我们用到前面讲的误差指标时，我们要改变这个设定。