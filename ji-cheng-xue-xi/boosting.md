##boosting 算法
![](/assets/31170C58-9CAC-4317-884A-77A4152769BD.png)



### 给定了一个训练集
它由一些 xi, yr 对组成。其中 x 是输入，y 是输出。
标签中会使用 -1 或 +1。其中 -1 表示 不在类别之中，+1 表示 在类别之中。因此这属于二元分类法
####时间步循环
我们将时间步称为小写 t。从时间步 1 一直到将来的更大时间步。我们把循环终止时间步称作大写 T，
 Foo t = 1 to T
 构造分布称为 D(t)（括号中内容为下标）。也就是样本中在特定时间 T 的分布。有了该分布，
####查找弱分类器
弱学习器输出一些假设。我们将结果称为h(t)。也就是在该时间步生成的假设。
该假设应当存在一些小误差。由于误差是一个比较小的数字，我们把它称为 ε(t)。
在培训集上，对于给定的特定分布，
返回的假设称为 h(t)。把有误差的假设称为 ε(t)。也就是说，对于潜在分布，假设与训练标签不一致的可能性非常小。
 ####处理
对整个时间步进行这样的处理，不断寻找每个时间步
存在微小误差 ε(t) 的假设 h(t)。不断构造新的分布。
最后输出最终假设。


####怎么得到分布


####怎么获得最终假设
 


